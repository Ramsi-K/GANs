{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7_QS6hRNwXFd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ramsi\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import torch, torchvision, os, PIL, pdb\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import make_grid\n",
        "from tqdm.auto import tqdm\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def show(tensor, num=25, wandbactive=0, name=\"\"):\n",
        "    data = tensor.detach().cpu()\n",
        "    grid = make_grid(data[:num], nrow=5).permute(1, 2, 0)\n",
        "\n",
        "    ## optional\n",
        "    if wandbactive == 1:\n",
        "        wandb.log({name: wandb.Image(grid.numpy().clip(0, 1))})\n",
        "\n",
        "    plt.imshow(grid.clip(0, 1))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "### hyperparameters and general parameters\n",
        "n_epochs = 10000\n",
        "batch_size = 128\n",
        "lr = 1e-4\n",
        "z_dim = 200\n",
        "device = \"cuda\"  # GPU\n",
        "\n",
        "cur_step = 0\n",
        "crit_cycles = 5\n",
        "gen_losses = []\n",
        "crit_losses = []\n",
        "show_step = 35\n",
        "save_step = 35\n",
        "\n",
        "wandbact = (\n",
        "    1  # yes, we want to track stats through weights and biases, optional\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "w0XuIgr0izgj"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "API key must be 40 characters long, yours was 23",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[2], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip install wandb -qqq\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwandb\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[43mwandb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPUT HERE YOUR WANDB KEY\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m#instructions are in the related video :)\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\ramsi\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\wandb\\sdk\\wandb_login.py:85\u001b[0m, in \u001b[0;36mlogin\u001b[1;34m(anonymous, key, relogin, host, force, timeout, verify)\u001b[0m\n\u001b[0;32m     83\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mlocals\u001b[39m())\n\u001b[0;32m     84\u001b[0m _verify \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mverify\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m---> 85\u001b[0m configured \u001b[38;5;241m=\u001b[39m _login(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _verify:\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m wandb_setup\n",
            "File \u001b[1;32mc:\\Users\\ramsi\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\wandb\\sdk\\wandb_login.py:311\u001b[0m, in \u001b[0;36m_login\u001b[1;34m(anonymous, key, relogin, host, force, timeout, _backend, _silent, _disable_warning, _entity)\u001b[0m\n\u001b[0;32m    309\u001b[0m key \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkey\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    310\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key:\n\u001b[1;32m--> 311\u001b[0m     \u001b[43mwlogin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfigure_api_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m logged_in:\n\u001b[0;32m    314\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m logged_in\n",
            "File \u001b[1;32mc:\\Users\\ramsi\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\wandb\\sdk\\wandb_login.py:195\u001b[0m, in \u001b[0;36m_WandbLogin.configure_api_key\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_settings\u001b[38;5;241m.\u001b[39m_notebook \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_settings\u001b[38;5;241m.\u001b[39msilent:\n\u001b[0;32m    189\u001b[0m     wandb\u001b[38;5;241m.\u001b[39mtermwarn(\n\u001b[0;32m    190\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf you\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mre specifying your api key in code, ensure this \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    191\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode is not shared publicly.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mConsider setting the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    192\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWANDB_API_KEY environment variable, or running \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    193\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`wandb login` from the command line.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    194\u001b[0m     )\n\u001b[1;32m--> 195\u001b[0m \u001b[43mapikey\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_key\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_settings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_session(key)\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_key \u001b[38;5;241m=\u001b[39m key\n",
            "File \u001b[1;32mc:\\Users\\ramsi\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\wandb\\sdk\\lib\\apikey.py:244\u001b[0m, in \u001b[0;36mwrite_key\u001b[1;34m(settings, key, api, anonymous)\u001b[0m\n\u001b[0;32m    241\u001b[0m _, suffix \u001b[38;5;241m=\u001b[39m key\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m key \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, key)\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(suffix) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m40\u001b[39m:\n\u001b[1;32m--> 244\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAPI key must be 40 characters long, yours was \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mlen\u001b[39m(key))\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m anonymous:\n\u001b[0;32m    247\u001b[0m     api\u001b[38;5;241m.\u001b[39mset_setting(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manonymous\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrue\u001b[39m\u001b[38;5;124m\"\u001b[39m, globally\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, persist\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "\u001b[1;31mValueError\u001b[0m: API key must be 40 characters long, yours was 23"
          ]
        }
      ],
      "source": [
        "#### optional\n",
        "!pip install wandb -qqq\n",
        "import wandb\n",
        "wandb.login(key='PUT HERE YOUR WANDB KEY')  #instructions are in the related video :)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SJX0alVUl8VQ"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "experiment_name = wandb.util.generate_id()\n",
        "\n",
        "myrun=wandb.init(\n",
        "    project=\"wgan\",\n",
        "    group=experiment_name,\n",
        "    config={\n",
        "        \"optimizer\":\"adam\",\n",
        "        \"model\":\"wgan gp\",\n",
        "        \"epoch\":\"1000\",\n",
        "        \"batch_size\":128\n",
        "    }\n",
        ")\n",
        "\n",
        "config=wandb.config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jb_krOBKm2Wv"
      },
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, z_dim=64, d_dim=16):\n",
        "        super(Generator, self).__init__()\n",
        "        self.z_dim = z_dim\n",
        "\n",
        "        self.gen = nn.Sequential(\n",
        "            ## ConvTranspose2d: in_channels, out_channels, kernel_size, stride=1, padding=0\n",
        "            ## Calculating new width and height: (n-1)*stride -2*padding +ks\n",
        "            ## n = width or height\n",
        "            ## ks = kernel size\n",
        "            ## we begin with a 1x1 image with z_dim number of channels (200)\n",
        "            nn.ConvTranspose2d(\n",
        "                z_dim, d_dim * 32, 4, 1, 0\n",
        "            ),  ## 4x4 (ch: 200, 512)\n",
        "            nn.BatchNorm2d(d_dim * 32),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(\n",
        "                d_dim * 32, d_dim * 16, 4, 2, 1\n",
        "            ),  ## 8x8 (ch: 512, 256)\n",
        "            nn.BatchNorm2d(d_dim * 16),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(\n",
        "                d_dim * 16, d_dim * 8, 4, 2, 1\n",
        "            ),  ## 16x16 (ch: 256, 128)\n",
        "            # (n-1)*stride -2*padding +ks = (8-1)*2-2*1+4=16\n",
        "            nn.BatchNorm2d(d_dim * 8),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(\n",
        "                d_dim * 8, d_dim * 4, 4, 2, 1\n",
        "            ),  ## 32x32 (ch: 128, 64)\n",
        "            nn.BatchNorm2d(d_dim * 4),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(\n",
        "                d_dim * 4, d_dim * 2, 4, 2, 1\n",
        "            ),  ## 64x64 (ch: 64, 32)\n",
        "            nn.BatchNorm2d(d_dim * 2),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(d_dim * 2, 3, 4, 2, 1),  ## 128x128 (ch: 32, 3)\n",
        "            nn.Tanh(),  ### produce result in the range from -1 to 1\n",
        "        )\n",
        "\n",
        "    def forward(self, noise):\n",
        "        x = noise.view(len(noise), self.z_dim, 1, 1)  # 128 x 200 x 1 x 1\n",
        "        return self.gen(x)\n",
        "\n",
        "\n",
        "def gen_noise(num, z_dim, device=\"cuda\"):\n",
        "    return torch.randn(num, z_dim, device=device)  # 128 x 200"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CNbxakfcyoB5"
      },
      "outputs": [],
      "source": [
        "class Critic(nn.Module):\n",
        "\n",
        "    def __init__(self, d_dim=16):\n",
        "\n",
        "        super(Critic, self).__init__()\n",
        "\n",
        "        self.crit = nn.Sequential(\n",
        "            # Conv2d: in_channels, out_channels, kernel_size, stride=1, padding=0\n",
        "            ## New width and height: # (n+2*pad-ks)//stride +1\n",
        "            nn.Conv2d(\n",
        "                3, d_dim, 4, 2, 1\n",
        "            ),  # (n+2*pad-ks)//stride +1 = (128+2*1-4)//2+1=64x64 (ch: 3,16)\n",
        "            nn.InstanceNorm2d(d_dim),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(d_dim, d_dim * 2, 4, 2, 1),  ## 32x32 (ch: 16, 32)\n",
        "            nn.InstanceNorm2d(d_dim * 2),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(d_dim * 2, d_dim * 4, 4, 2, 1),  ## 16x16 (ch: 32, 64)\n",
        "            nn.InstanceNorm2d(d_dim * 4),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(d_dim * 4, d_dim * 8, 4, 2, 1),  ## 8x8 (ch: 64, 128)\n",
        "            nn.InstanceNorm2d(d_dim * 8),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(d_dim * 8, d_dim * 16, 4, 2, 1),  ## 4x4 (ch: 128, 256)\n",
        "            nn.InstanceNorm2d(d_dim * 16),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(\n",
        "                d_dim * 16, 1, 4, 1, 0\n",
        "            ),  # (n+2*pad-ks)//stride +1=(4+2*0-4)//1+1= 1X1 (ch: 256,1)\n",
        "        )\n",
        "\n",
        "    def forward(self, image):\n",
        "\n",
        "        # image: 128 x 3 x 128 x 128\n",
        "\n",
        "        crit_pred = self.crit(image)  # 128 x 1 x 1 x 1\n",
        "\n",
        "        return crit_pred.view(len(crit_pred), -1)  ## 128 x 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6wV46jNyptu1"
      },
      "outputs": [],
      "source": [
        "## optional, init your weights in different ways\n",
        "def init_weights(m):\n",
        "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
        "        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n",
        "        torch.nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    if isinstance(m, nn.BatchNorm2d):\n",
        "        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n",
        "        torch.nn.init.constant_(m.bias, 0)\n",
        "\n",
        "\n",
        "##gen=gen.apply(init_weights)\n",
        "##crit=crit.apply(init_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e_z0Zh8f3Uj6"
      },
      "outputs": [],
      "source": [
        "# load dataset\n",
        "import gdown, zipfile\n",
        "\n",
        "url = \"https://drive.google.com/uc?id=1cNIac61PSA_LqDFYFUeyaQYekYPc75NH\"\n",
        "path = \"data/celeba\"\n",
        "download_path = f\"{path}/img_align_celeba.zip\"\n",
        "\n",
        "if not os.path.exists(path):\n",
        "    os.makedirs(path)\n",
        "\n",
        "gdown.download(url, download_path, quiet=False)\n",
        "\n",
        "with zipfile.ZipFile(download_path, \"r\") as ziphandler:\n",
        "    ziphandler.extractall(path)\n",
        "\n",
        "\n",
        "#### Alternative download address:\n",
        "# Celebra gdrive: https://drive.google.com/drive/folders/0B7EVK8r0v71pTUZsaXdaSnZBZzg?resourcekey=0-rJlzl934LzC-Xp28GeIBzQ\n",
        "# Kaggle: https://www.kaggle.com/jessicali9530/celeba-dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-0lcXtgz6fDQ"
      },
      "outputs": [],
      "source": [
        "### Dataset, DataLoader, declare gen,crit, test dataset\n",
        "\n",
        "\n",
        "class Dataset(Dataset):\n",
        "    def __init__(self, path, size=128, lim=10000):\n",
        "        self.sizes = [size, size]\n",
        "        items, labels = [], []\n",
        "\n",
        "        for data in os.listdir(path)[:lim]:\n",
        "            # path: './data/celeba/img_align_celeba'\n",
        "            # data: '114568.jpg\n",
        "            item = os.path.join(path, data)\n",
        "            items.append(item)\n",
        "            labels.append(data)\n",
        "        self.items = items\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.items)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        data = PIL.Image.open(self.items[idx]).convert(\"RGB\")  # (178,218)\n",
        "        data = np.asarray(\n",
        "            torchvision.transforms.Resize(self.sizes)(data)\n",
        "        )  # 128 x 128 x 3\n",
        "        data = np.transpose(data, (2, 0, 1)).astype(\n",
        "            np.float32, copy=False\n",
        "        )  # 3 x 128 x 128 # from 0 to 255\n",
        "        data = torch.from_numpy(data).div(255)  # from 0 to 1\n",
        "        return data, self.labels[idx]\n",
        "\n",
        "\n",
        "## Dataset\n",
        "data_path = \"./data/celeba/img_align_celeba\"\n",
        "ds = Dataset(data_path, size=128, lim=10000)\n",
        "\n",
        "## DataLoader\n",
        "dataloader = DataLoader(ds, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "## Models\n",
        "gen = Generator(z_dim).to(device)\n",
        "crit = Critic().to(device)\n",
        "\n",
        "## Optimizers\n",
        "gen_opt = torch.optim.Adam(gen.parameters(), lr=lr, betas=(0.5, 0.9))\n",
        "crit_opt = torch.optim.Adam(crit.parameters(), lr=lr, betas=(0.5, 0.9))\n",
        "\n",
        "## Initializations\n",
        "##gen=gen.apply(init_weights)\n",
        "##crit=crit.apply(init_weights)\n",
        "\n",
        "# wandb optional\n",
        "if wandbact == 1:\n",
        "    wandb.watch(gen, log_freq=100)\n",
        "    wandb.watch(crit, log_freq=100)\n",
        "\n",
        "x, y = next(iter(dataloader))\n",
        "show(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oaTz8qmn9h6-"
      },
      "outputs": [],
      "source": [
        "## gradient penalty calculation\n",
        "\n",
        "\n",
        "def get_gp(real, fake, crit, alpha, gamma=10):\n",
        "    mix_images = real * alpha + fake * (1 - alpha)  # 128 x 3 x 128 x 128\n",
        "    mix_scores = crit(mix_images)  # 128 x 1\n",
        "\n",
        "    gradient = torch.autograd.grad(\n",
        "        inputs=mix_images,\n",
        "        outputs=mix_scores,\n",
        "        grad_outputs=torch.ones_like(mix_scores),\n",
        "        retain_graph=True,\n",
        "        create_graph=True,\n",
        "    )[\n",
        "        0\n",
        "    ]  # 128 x 3 x 128 x 128\n",
        "\n",
        "    gradient = gradient.view(len(gradient), -1)  # 128 x 49152\n",
        "    gradient_norm = gradient.norm(2, dim=1)\n",
        "    gp = gamma * ((gradient_norm - 1) ** 2).mean()\n",
        "\n",
        "    return gp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JW9H2tlICYI8"
      },
      "outputs": [],
      "source": [
        "## Save and load checkpoints\n",
        "\n",
        "root_path = \"./data/\"\n",
        "\n",
        "\n",
        "def save_checkpoint(name):\n",
        "    torch.save(\n",
        "        {\n",
        "            \"epoch\": epoch,\n",
        "            \"model_state_dict\": gen.state_dict(),\n",
        "            \"optimizer_state_dict\": gen_opt.state_dict(),\n",
        "        },\n",
        "        f\"{root_path}G-{name}.pkl\",\n",
        "    )\n",
        "\n",
        "    torch.save(\n",
        "        {\n",
        "            \"epoch\": epoch,\n",
        "            \"model_state_dict\": crit.state_dict(),\n",
        "            \"optimizer_state_dict\": crit_opt.state_dict(),\n",
        "        },\n",
        "        f\"{root_path}C-{name}.pkl\",\n",
        "    )\n",
        "\n",
        "    print(\"Saved checkpoint\")\n",
        "\n",
        "\n",
        "def load_checkpoint(name):\n",
        "    checkpoint = torch.load(f\"{root_path}G-{name}.pkl\")\n",
        "    gen.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "    gen_opt.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
        "\n",
        "    checkpoint = torch.load(f\"{root_path}C-{name}.pkl\")\n",
        "    crit.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "    crit_opt.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
        "\n",
        "    print(\"Loaded checkpoint\")\n",
        "\n",
        "\n",
        "# load_checkpoint('final-wgan-noinit')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y8QlaEw4EXED"
      },
      "outputs": [],
      "source": [
        "#!cp C-final* ./data/\n",
        "#!cp G-final* ./data/\n",
        "# epoch=1\n",
        "# save_checkpoint(\"test\")\n",
        "# load_checkpoint(\"test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Kt-QSmiEhG6"
      },
      "outputs": [],
      "source": [
        "## Training loop\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    for real, _ in tqdm(dataloader):\n",
        "        cur_bs = len(real)  # 128\n",
        "        real = real.to(device)\n",
        "\n",
        "        ### CRITIC\n",
        "        mean_crit_loss = 0\n",
        "        for _ in range(crit_cycles):\n",
        "            crit_opt.zero_grad()\n",
        "\n",
        "            noise = gen_noise(cur_bs, z_dim)\n",
        "            fake = gen(noise)\n",
        "            crit_fake_pred = crit(fake.detach())\n",
        "            crit_real_pred = crit(real)\n",
        "\n",
        "            alpha = torch.rand(\n",
        "                len(real), 1, 1, 1, device=device, requires_grad=True\n",
        "            )  # 128 x 1 x 1 x 1\n",
        "            gp = get_gp(real, fake.detach(), crit, alpha)\n",
        "\n",
        "            crit_loss = crit_fake_pred.mean() - crit_real_pred.mean() + gp\n",
        "\n",
        "            mean_crit_loss += crit_loss.item() / crit_cycles\n",
        "\n",
        "            crit_loss.backward(retain_graph=True)\n",
        "            crit_opt.step()\n",
        "\n",
        "        crit_losses += [mean_crit_loss]\n",
        "\n",
        "        ### GENERATOR\n",
        "        gen_opt.zero_grad()\n",
        "        noise = gen_noise(cur_bs, z_dim)\n",
        "        fake = gen(noise)\n",
        "        crit_fake_pred = crit(fake)\n",
        "\n",
        "        gen_loss = -crit_fake_pred.mean()\n",
        "        gen_loss.backward()\n",
        "        gen_opt.step()\n",
        "\n",
        "        gen_losses += [gen_loss.item()]\n",
        "\n",
        "        ### Stats\n",
        "\n",
        "        if wandbact == 1:\n",
        "            wandb.log(\n",
        "                {\n",
        "                    \"Epoch\": epoch,\n",
        "                    \"Step\": cur_step,\n",
        "                    \"Critic loss\": mean_crit_loss,\n",
        "                    \"Gen loss\": gen_loss,\n",
        "                }\n",
        "            )\n",
        "\n",
        "        if cur_step % save_step == 0 and cur_step > 0:\n",
        "            print(\"Saving checkpoint: \", cur_step, save_step)\n",
        "            save_checkpoint(\"latest\")\n",
        "\n",
        "        if cur_step % show_step == 0 and cur_step > 0:\n",
        "            show(fake, wandbactive=1, name=\"fake\")\n",
        "            show(real, wandbactive=1, name=\"real\")\n",
        "\n",
        "            gen_mean = sum(gen_losses[-show_step:]) / show_step\n",
        "            crit_mean = sum(crit_losses[-show_step:]) / show_step\n",
        "            print(\n",
        "                f\"Epoch: {epoch}: Step {cur_step}: Generator loss: {gen_mean}, critic loss: {crit_mean}\"\n",
        "            )\n",
        "\n",
        "            plt.plot(\n",
        "                range(len(gen_losses)),\n",
        "                torch.Tensor(gen_losses),\n",
        "                label=\"Generator Loss\",\n",
        "            )\n",
        "\n",
        "            plt.plot(\n",
        "                range(len(gen_losses)),\n",
        "                torch.Tensor(crit_losses),\n",
        "                label=\"Critic Loss\",\n",
        "            )\n",
        "\n",
        "            plt.ylim(-150, 150)\n",
        "            plt.legend()\n",
        "            plt.show()\n",
        "\n",
        "        cur_step += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xkgGRFqMHSII"
      },
      "outputs": [],
      "source": [
        "# number of steps per epoch\n",
        "# 10000 / 128 = 78.125\n",
        "# 50000 / 128 = 390.625"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "53_FHIdBps4K"
      },
      "outputs": [],
      "source": [
        "#### Generate new faces\n",
        "noise = gen_noise(batch_size, z_dim)\n",
        "fake = gen(noise)\n",
        "show(fake)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P2Bo_j9ewSAu"
      },
      "outputs": [],
      "source": [
        "plt.imshow(fake[16].detach().cpu().permute(1, 2, 0).squeeze().clip(0, 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zOgMT09WxQFW"
      },
      "outputs": [],
      "source": [
        "from mpl_toolkits.axes_grid1 import ImageGrid\n",
        "\n",
        "# MORPHING, interpolation between points in latent space\n",
        "gen_set = []\n",
        "z_shape = [1, 200, 1, 1]\n",
        "rows = 4\n",
        "steps = 17\n",
        "\n",
        "for i in range(rows):\n",
        "    z1, z2 = torch.randn(z_shape), torch.randn(z_shape)\n",
        "    for alpha in np.linspace(0, 1, steps):\n",
        "        z = alpha * z1 + (1 - alpha) * z2\n",
        "        res = gen(z.cuda())[0]\n",
        "        gen_set.append(res)\n",
        "\n",
        "fig = plt.figure(figsize=(25, 11))\n",
        "grid = ImageGrid(fig, 111, nrows_ncols=(rows, steps), axes_pad=0.1)\n",
        "\n",
        "for ax, img in zip(grid, gen_set):\n",
        "    ax.axis(\"off\")\n",
        "    res = img.cpu().detach().permute(1, 2, 0)\n",
        "    res = res - res.min()\n",
        "    res = res / (res.max() - res.min())\n",
        "    ax.imshow(res.clip(0, 1.0))\n",
        "\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Advanced GAN - Generative A.I course by Ideami",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
